{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Dogs Dataset\n",
    "[Stanford Dogs](http://vision.stanford.edu/aditya86/ImageNetDogs/) is a dataset of 120 dog breeds. In this project I am using YOLOv8 to train a model to detect these breeds. The dataset is divided into 120 folders, each containing images of a specific breed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "\n",
    "# define paths\n",
    "ROOT_DIR = f\"{CURRENT_DIR}/pets\"\n",
    "ANNOTATIONS_DIR = os.path.join(ROOT_DIR, \"Annotation\")\n",
    "IMAGES_DIR = os.path.join(ROOT_DIR, \"Images\")\n",
    "YOLO_LABELS_DIR = os.path.join(ROOT_DIR, \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['silky_terrier', 'Scottish_deerhound', 'Chesapeake_Bay_retriever', 'Ibizan_hound', 'wire-haired_fox_terrier', 'Saluki', 'cocker_spaniel', 'schipperke', 'borzoi', 'Pembroke', 'komondor', 'Staffordshire_bullterrier', 'standard_poodle', 'Eskimo_dog', 'English_foxhound', 'golden_retriever', 'Sealyham_terrier', 'Japanese_spaniel', 'miniature_schnauzer', 'malamute', 'malinois', 'Pekinese', 'giant_schnauzer', 'Mexican_hairless', 'Doberman', 'standard_schnauzer', 'dhole', 'German_shepherd', 'Bouvier_des_Flandres', 'Siberian_husky', 'Norwich_terrier', 'Irish_terrier', 'Norfolk_terrier', 'Saint_Bernard', 'Border_terrier', 'briard', 'Tibetan_mastiff', 'bull_mastiff', 'Maltese_dog', 'Kerry_blue_terrier', 'kuvasz', 'Greater_Swiss_Mountain_dog', 'Lakeland_terrier', 'Blenheim_spaniel', 'basset', 'West_Highland_white_terrier', 'Chihuahua', 'Border_collie', 'redbone', 'Irish_wolfhound', 'bluetick', 'miniature_poodle', 'Cardigan', 'EntleBucher', 'Norwegian_elkhound', 'German_short-haired_pointer', 'Bernese_mountain_dog', 'papillon', 'Tibetan_terrier', 'Gordon_setter', 'American_Staffordshire_terrier', 'vizsla', 'kelpie', 'Weimaraner', 'miniature_pinscher', 'boxer', 'chow', 'Old_English_sheepdog', 'pug', 'Rhodesian_ridgeback', 'Scotch_terrier', 'Shih-Tzu', 'affenpinscher', 'whippet', 'Sussex_spaniel', 'otterhound', 'flat-coated_retriever', 'English_setter', 'Italian_greyhound', 'Labrador_retriever', 'collie', 'cairn', 'Rottweiler', 'Australian_terrier', 'toy_terrier', 'Shetland_sheepdog', 'African_hunting_dog', 'Newfoundland', 'Walker_hound', 'Lhasa', 'beagle', 'Samoyed', 'Great_Dane', 'Airedale', 'bloodhound', 'Irish_setter', 'keeshond', 'Dandie_Dinmont', 'basenji', 'Bedlington_terrier', 'Appenzeller', 'clumber', 'toy_poodle', 'Great_Pyrenees', 'English_springer', 'Afghan_hound', 'Brittany_spaniel', 'Welsh_springer_spaniel', 'Boston_bull', 'dingo', 'soft-coated_wheaten_terrier', 'curly-coated_retriever', 'French_bulldog', 'Irish_water_spaniel', 'Pomeranian', 'Brabancon_griffon', 'Yorkshire_terrier', 'groenendael', 'Leonberg', 'black-and-tan_coonhound']\n",
      "120\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# get every type of dog\n",
    "def get_dog_types():\n",
    "    dog_types = []\n",
    "    for folder in os.listdir(ANNOTATIONS_DIR):\n",
    "        if folder == \".DS_Store\":\n",
    "            continue\n",
    "        for annotation_file in os.listdir(os.path.join(ANNOTATIONS_DIR, folder)):\n",
    "            #print(annotation_file)\n",
    "            tree = ET.parse(os.path.join(ANNOTATIONS_DIR,folder, annotation_file))\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall(\"object\"):\n",
    "                name = obj.find(\"name\").text\n",
    "                if name not in dog_types:\n",
    "                    dog_types.append(name)\n",
    "    return dog_types\n",
    "\n",
    "CLASSES = get_dog_types()\n",
    "print(CLASSES)\n",
    "print(len(CLASSES))\n",
    "def class_number(name):\n",
    "    return CLASSES.index(name)\n",
    "\n",
    "print(class_number(\"Chihuahua\"))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create yolo labels directory\n",
    "if not os.path.exists(YOLO_LABELS_DIR):\n",
    "    os.makedirs(YOLO_LABELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the folders in the annotations directory\n",
    "folders = os.listdir(ANNOTATIONS_DIR)\n",
    "for folder in folders:\n",
    "    os.makedirs(os.path.join(YOLO_LABELS_DIR, folder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all of the yolo-labels\n",
    "# this just takes the first object in the xml file, and creates a yolo label for it, \n",
    "# note some xml files have multiple objects, so this is not a complete solution\n",
    "def parse_xml(file):\n",
    "    # parse the xml file\n",
    "    tree = ET.parse(os.path.join(ANNOTATIONS_DIR, folder, file))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # get the image size\n",
    "    size = root.find(\"size\")\n",
    "    width = int(size.find(\"width\").text)\n",
    "    height = int(size.find(\"height\").text)\n",
    "\n",
    "    # create a new file for the yolo labels\n",
    "    with open(os.path.join(YOLO_LABELS_DIR, folder, file.replace(\".xml\", \".txt\")), \"w\") as f:\n",
    "        # go through each object in the xml file\n",
    "        for obj in root.findall(\"object\"):\n",
    "            # get the class name\n",
    "            class_name = obj.find(\"name\").text\n",
    "\n",
    "            # get the bounding box\n",
    "            bndbox = obj.find(\"bndbox\")\n",
    "            xmin = int(bndbox.find(\"xmin\").text)\n",
    "            ymin = int(bndbox.find(\"ymin\").text)\n",
    "            xmax = int(bndbox.find(\"xmax\").text)\n",
    "            ymax = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "            # calculate the center of the bounding box\n",
    "            x = (xmin + xmax) / 2 / width\n",
    "            y = (ymin + ymax) / 2 / height\n",
    "\n",
    "            # calculate the width and height of the bounding box\n",
    "            w = (xmax - xmin) / width\n",
    "            h = (ymax - ymin) / height\n",
    "\n",
    "            class_name = class_number(class_name)\n",
    "\n",
    "            return f'{class_name} {x} {y} {w} {h}\\n'\n",
    "\n",
    "\n",
    "# go through each folder in the annotations directory, and get all of the xml files\n",
    "for folder in folders:\n",
    "    if folder == \".DS_Store\": continue\n",
    "    for file in os.listdir(os.path.join(ANNOTATIONS_DIR, folder)):\n",
    "        output = parse_xml(file)\n",
    "        # place output in yolo-labels directory\n",
    "        with open(os.path.join(YOLO_LABELS_DIR, folder, file + \".txt\"), \"w\") as f:\n",
    "            f.write(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20580\n",
      "/Users/nickaloyd/Documents/Data Mining Final Project copy/pets/Images/n02097658-silky_terrier/n02097658_26.jpg\n"
     ]
    }
   ],
   "source": [
    "# Process annotations\n",
    "image_paths = []\n",
    "for class_folder in os.listdir(IMAGES_DIR):\n",
    "    class_folder_path = os.path.join(IMAGES_DIR, class_folder)\n",
    "    \n",
    "    if not os.path.isdir(class_folder_path): continue\n",
    "\n",
    "    for image_filename in os.listdir(class_folder_path):\n",
    "        #print(image_filename)\n",
    "        image_paths.append(os.path.join(class_folder_path, image_filename))\n",
    "\n",
    "print(len(image_paths))\n",
    "print(image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split dataset into training and validation sets\n",
    "train_images, val_images = train_test_split(image_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# select only 10 images for testing, to speed up the process\n",
    "train_images = train_images\n",
    "val_images = val_images\n",
    "\n",
    "# write image paths to train.txt and val.txt\n",
    "with open(os.path.join(ROOT_DIR, \"train.txt\"), \"w\") as f:\n",
    "    f.writelines(f\"{img}\\n\" for img in train_images)\n",
    "with open(os.path.join(ROOT_DIR, \"val.txt\"), \"w\") as f:\n",
    "    f.writelines(f\"{img}\\n\" for img in val_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory structure:\n",
    "--------------------\n",
    "\n",
    "``` text\n",
    "data/\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   │   ├── img1.jpg\n",
    "│   │   ├── img2.jpg\n",
    "│   ├── labels/\n",
    "│       ├── img1.txt\n",
    "│       ├── img2.txt\n",
    "├── val/\n",
    "    ├── images/\n",
    "    │   ├── img3.jpg\n",
    "    ├── labels/\n",
    "        ├── img3.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new folder tree for the training and validation images\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TRAIN_IMAGES_DIR = os.path.join(TRAIN_DIR, \"images\")\n",
    "TRAIN_LABELS_DIR = os.path.join(TRAIN_DIR, \"labels\")\n",
    "\n",
    "VAL_DIR = os.path.join(DATA_DIR, \"val\")\n",
    "VAL_IMAGES_DIR = os.path.join(VAL_DIR, \"images\")\n",
    "VAL_LABELS_DIR = os.path.join(VAL_DIR, \"labels\")\n",
    "\n",
    "os.makedirs(TRAIN_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(TRAIN_LABELS_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_LABELS_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# loop through each training image\n",
    "for i, image_path in enumerate(train_images):\n",
    "    # derive label path\n",
    "    label_path = image_path.replace(IMAGES_DIR, YOLO_LABELS_DIR).replace('.jpg', '.txt')\n",
    "    \n",
    "    # construct new file paths for images and labels\n",
    "    new_train_image_path = f\"{TRAIN_IMAGES_DIR}/{i}.jpg\"\n",
    "    new_train_label_path = f\"{TRAIN_LABELS_DIR}/{i}.txt\"\n",
    "\n",
    "    new_val_image_path = f\"{VAL_IMAGES_DIR}/{i}.jpg\"\n",
    "    new_val_label_path = f\"{VAL_LABELS_DIR}/{i}.txt\"\n",
    "    \n",
    "    # copy image and label to the new directories\n",
    "    shutil.copy(image_path, new_train_image_path)\n",
    "    shutil.copy(label_path, new_train_label_path)\n",
    "    shutil.copy(image_path, new_val_image_path)\n",
    "    shutil.copy(label_path, new_val_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation complete!\n"
     ]
    }
   ],
   "source": [
    "# create data.yaml\n",
    "import yaml\n",
    "with open(os.path.join(DATA_DIR, \"data.yaml\"), \"w\") as f:\n",
    "    yaml_content = {\n",
    "        'train': os.path.join(ROOT_DIR, \"train.txt\"),\n",
    "        'val': os.path.join(ROOT_DIR, \"val.txt\"),\n",
    "        'nc': len(CLASSES),\n",
    "        'names': CLASSES\n",
    "    }\n",
    "    yaml.dump(yaml_content, f)\n",
    "\n",
    "print(\"Dataset preparation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation .txt files\n",
    "with open(os.path.join(ROOT_DIR, \"train.txt\"), \"w\") as f:\n",
    "    f.writelines(f\"{TRAIN_IMAGES_DIR}/{i}.jpg\\n\" for i in range(len(train_images)))\n",
    "with open(os.path.join(ROOT_DIR, \"val.txt\"), \"w\") as f:\n",
    "    f.writelines(f\"{VAL_IMAGES_DIR}/{i}.jpg\\n\" for i in range(len(val_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yolo task=detect mode=train model=yolov8n.pt data=data/data.yaml epochs=50 imgsz=640"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
